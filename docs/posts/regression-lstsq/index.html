<!DOCTYPE html>
<html lang="ja-jp">
<title>線形回帰メモ 最小二乗法 | Chanomic Blog</title>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.84.0" />


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-152083322-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-152083322-1');
</script>



<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="canonical" href="https://bombrary.github.io/blog/posts/regression-lstsq/">
<link rel="alternate" type="application/rss+xml" href="" title="Chanomic Blog">
<link rel="stylesheet" href="https://bombrary.github.io/blog/css/theme.css">
<link rel="stylesheet" href="https://bombrary.github.io/blog/css/classes.css">
<link rel="stylesheet" href="https://bombrary.github.io/blog/css/syntax.css">

<link rel="stylesheet" href="https://bombrary.github.io/blog/css/math.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
                                                                                                                                                                                  onload="renderMathInElement(document.body);"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {delimiters: [
      {left: "$$", right: "$$", display: true},
      {left: "$", right: "$", display: false}]
    });
  });
</script>



<header class="dark">
  <h2><a href="https://bombrary.github.io/blog/">Chanomic Blog</a></h2>
  <nav>
    
  </nav>
</header>


<article>
  <header>
    <h1><a href="https://bombrary.github.io/blog/posts/regression-lstsq/">線形回帰メモ 最小二乗法</a></h1>
    <div class="meta">
      
      <div class="pub-date">
        <time datetime="2021-06-20T22:10:00&#43;09:00">June 20, 2021</time>
      </div>
      
      
      <div class="lastmod-date">
        <div class="lastmod-date__label">(last modified:</div>
        <time datetime="2021-06-20T22:10:00&#43;09:00">June 28, 2021</time>
        <div class="lastmod-date__label">)</div>
      </div>
      
    </div>
    
    <div class="tags-categories">
      <div class="tags">
        <p>tags: </p>
        <ul class="tags_list">
          <li class="tags_item"><a href="https://bombrary.github.io/blog//tags/%e6%9c%80%e5%b0%8f%e4%ba%8c%e4%b9%97%e6%b3%95/">最小二乗法</a></li><li class="tags_item"><a href="https://bombrary.github.io/blog//tags/%e7%b7%9a%e5%9e%8b%e4%bb%a3%e6%95%b0/">線型代数</a></li><li class="tags_item"><a href="https://bombrary.github.io/blog//tags/%e7%b7%9a%e5%bd%a2%e5%9b%9e%e5%b8%b0/">線形回帰</a></li>
        </ul>
        
      </div>
      <div class="categories">
        <p>categories: </p>
        
        <ul class="categories_list">
           <li class="tags_item"><a href="https://bombrary.github.io/blog//categories/%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92/">機械学習</a></li> <li class="tags_item"><a href="https://bombrary.github.io/blog//categories/julia/">Julia</a></li>
        </ul>
        
      </div>
    </div>
  </header>
  
    <aside>
      <h2>目次</h2>
      <nav id="TableOfContents">
  <ul>
    <li><a href="#問題設定1">問題設定(1)</a></li>
    <li><a href="#コスト関数の最小値を求める1">コスト関数の最小値を求める(1)</a>
      <ul>
        <li><a href="#コスト関数の行列表現">コスト関数の行列表現</a></li>
        <li><a href="#コスト関数の勾配">コスト関数の勾配</a></li>
        <li><a href="#極小値であること">極小値であること</a></li>
        <li><a href="#最小値であること">最小値であること</a></li>
      </ul>
    </li>
    <li><a href="#juliaによる実装">Juliaによる実装</a>
      <ul>
        <li><a href="#サンプルデータの作成">サンプルデータの作成</a></li>
        <li><a href="#wの計算">wの計算</a></li>
      </ul>
    </li>
    <li><a href="#問題設定2---基底関数を含む場合">問題設定(2) - 基底関数を含む場合</a></li>
    <li><a href="#コスト関数の最小値を求める-2">コスト関数の最小値を求める (2)</a></li>
    <li><a href="#juliaによる実装-2">Juliaによる実装 (2)</a>
      <ul>
        <li><a href="#サンプルデータの作成-2">サンプルデータの作成 (2)</a></li>
        <li><a href="#wの計算-2">wの計算 (2)</a></li>
      </ul>
    </li>
    <li><a href="#計算量">計算量</a></li>
  </ul>
</nav>
    </aside>
    
  <p>学校の授業で勉強はしたが、自分で考えてまとめたことはなかったのでここに記しておく。</p>
<h2 id="問題設定1">問題設定(1)</h2>
<p>$\bm{y} = (y^{(1)}, y^{(2)}, \ldots, y^{(N)})^T,\ \bm{x}_i = (1, x_1^{(i)}, x_2^{(i)}, \ldots, x_D^{(i)})^T$
とおく。$(\bm{x}_i, y_i),\ i = 1, 2, \ldots, N$ がデータとして与えられている。このとき、入力と出力の間に</p>
<p>$$
\begin{aligned}
y
&amp;= h_{\bm{w}}(\bm{x})\\
&amp;:= w_0 + w_1x_1 + w_2x_2 + \cdots + w_Dx_D\\
&amp;= \bm{w}^T\bm{x}
\end{aligned}
$$</p>
<p>が成り立つと仮定し、これに適する$\bm{w}$を見つけたい。「適する」とは具体的に何なのかというと、ここでは予測とデータとの二乗誤差の和</p>
<p>$$
J(\bm{w}) = \frac{1}{2} \sum_{i=1}^{N} (h_{\bm{w}}(\bm{x}_i) - y^{(i)})^2
$$</p>
<p>が最小となる $\bm{w}$ を求める。この $J$ については呼び名がいくつかあるが、ここではコスト関数と呼ぶ。
係数 $1/2$ は微分した時に出てくる $2$ を消し去るための便宜的なものであり、つける必然はない。</p>
<h2 id="コスト関数の最小値を求める1">コスト関数の最小値を求める(1)</h2>
<h3 id="コスト関数の行列表現">コスト関数の行列表現</h3>
<p>まず $J$ を行列だけで表現してみる。</p>
<p>$$
\begin{aligned}
J(\bm{w})
&amp;= \frac{1}{2} \sum_{i=1}^{N} (\bm{w}^T\bm{x}_i - y^{(i)})^2\\
&amp;= \frac{1}{2} \sum_{i=1}^{N} (\bm{x}_i^T\bm{w} - y^{(i)})^2\\
&amp;= \frac{1}{2}
\begin{pmatrix}
\bm{x}_1^T\bm{w} - y^{(1)}\\
\bm{x}_2^T\bm{w} - y^{(2)}\\
\vdots\\
\bm{x}_N^T\bm{w} - y^{(N)}\\
\end{pmatrix}^T
\begin{pmatrix}
\bm{x}_1^T\bm{w} - y^{(1)}\\
\bm{x}_2^T\bm{w} - y^{(2)}\\
\vdots\\
\bm{x}_N^T\bm{w} - y^{(N)}\\
\end{pmatrix}\\
&amp;= \frac{1}{2}
\left(
\begin{pmatrix}
\bm{x}_1^T\bm{w}\\
\bm{x}_2^T\bm{w}\\
\vdots\\
\bm{x}_N^T\bm{w}\\
\end{pmatrix} - \bm{y}
\right)^T
\left(
\begin{pmatrix}
\bm{x}_1^T\bm{w}\\
\bm{x}_2^T\bm{w}\\
\vdots\\
\bm{x}_N^T\bm{w}\\
\end{pmatrix} - \bm{y}
\right)
\end{aligned}
$$</p>
<p>ここで、</p>
<p>$$
X = \begin{pmatrix}
\bm{x}_1^T \\ \bm{x}_2^T \\ \vdots \\ \bm{x}_N^T
\end{pmatrix}
$$</p>
<p>とおくと、</p>
<p>$$
\begin{aligned}
J(\bm{w})
&amp;= \frac{1}{2}
\left(
\begin{pmatrix}
\bm{x}_1^T\bm{w}\\
\bm{x}_2^T\bm{w}\\
\vdots\\
\bm{x}_N^T\bm{w}\\
\end{pmatrix} - \bm{y}
\right)^T
\left(
\begin{pmatrix}
\bm{x}_1^T\bm{w}\\
\bm{x}_2^T\bm{w}\\
\vdots\\
\bm{x}_N^T\bm{w}\\
\end{pmatrix} - \bm{y}
\right)\\
&amp;= \frac{1}{2}
\left( X\bm{w} - \bm{y} \right)^T
\left( X\bm{w} - \bm{y} \right)
\end{aligned}
$$</p>
<h3 id="コスト関数の勾配">コスト関数の勾配</h3>
<p>$J$ の勾配を求めるために、式を展開する。</p>
<p>$$
\begin{aligned}
J(\bm{w})
&amp;= \frac{1}{2}
\left( \bm{w}^TX^T - \bm{y}^T \right)
\left( X\bm{w} - \bm{y} \right)\\
&amp;= \frac{1}{2}
\left(
\bm{w}^TX^TX\bm{w} - \bm{w}^TX^T\bm{y} -\bm{y}^TX\bm{w} + \bm{y}^T\bm{y}
\right)
\end{aligned}
$$</p>
<p>$J$ の全ての項はスカラーだから、$\bm{w}^TX^T\bm{y} = \bm{y}^TX\bm{w}$が成り立つ。よって、</p>
<p>$$
\begin{aligned}
J(\bm{w})
&amp;= \frac{1}{2}
\left(
\bm{w}^TX^TX\bm{w} - 2\bm{y}^TX\bm{w} + \bm{y}^T\bm{y}
\right)
\end{aligned}
$$</p>
<p>二次形式の微分とベクトルの微分</p>
<p>$$
\begin{aligned}
\frac{\partial}{\partial \bm{x}} \bm{x}^TA\bm{x} &amp;= (A + A^T) \bm{x} \\
\frac{\partial}{\partial \bm{x}} \bm{a}^T\bm{x} &amp;= \bm{a}
\end{aligned}
$$</p>
<p>に注意すると、</p>
<p>$$
\begin{aligned}
\frac{\partial J(\bm{w})}{\partial \bm{w}}
&amp;= \frac{1}{2}
\left(
(X^TX + (X^TX)^T) \bm{w} - 2X^T\bm{y}
\right)\\
&amp;= \frac{1}{2}
\left(
2X^TX \bm{w} - 2X^T\bm{y}
\right)\\
&amp;= X^TX \bm{w} - X^T\bm{y}
\end{aligned}
$$</p>
<p>これで勾配が導出できた。係数 $1/2$ がうまく消えてくれたことに注目。</p>
<p>早速&quot;勾配 = 0&quot;を解いてみる。その解を $\bm{w}_0$とすると、$X^TX$が正則であると仮定して、</p>
<p>$$
\begin{aligned}
&amp; \quad \frac{\partial J(\bm{w}_0)}{\partial \bm{w}} = \bm{0} \\
\Leftrightarrow &amp; \quad  X^TX \bm{w}_0 = X^T\bm{y} \\
\Leftrightarrow &amp; \quad  \bm{w}_0 = \left( X^TX \right)^{-1} X^T \bm{y}
\end{aligned}
$$</p>
<h3 id="極小値であること">極小値であること</h3>
<p>さて、これは本当に極小値なのだろうか。
それを確かめるべく、ヘッセ行列を計算してみる。
もし $\bm{w}$ に対応するヘッセ行列が正定値行列なら、それは極小値である。</p>
<p>一般に、
$\displaystyle \frac{\partial f}{\partial \bm{x}} = \bm{a}$
なら $\displaystyle \frac{\partial f}{\partial \bm{x}^T} = \bm{a}^T$ だから、</p>
<p>$$
\begin{aligned}
\frac{\partial J(\bm{w})}{\partial \bm{w}^T}
&amp;= \bm{w}^TXX^T  - \bm{y}^TX^T
\end{aligned}
$$</p>
<p>よって、ヘッセ行列は、</p>
<p>$$
\begin{aligned}
\frac{\partial J(\bm{w})}{\partial \bm{w}^T\bm{w}}
&amp;= X^TX
\end{aligned}
$$</p>
<p>これはどうやら $\bm{w}$ によらない行列になるようだ。
一般に $\bm{x}^T\bm{x} \ge 0$ となることに注意すると、
任意の $\bm{z} \neq \bm{0}$ について、</p>
<p>$$
\begin{aligned}
\bm{z}^T(X^TX)\bm{z} = (X\bm{z})^T(X\bm{z}) \ge 0
\end{aligned}
$$</p>
<p>であるから、$X^TX$ は半正定値行列である。
このことから、$J$ が凸関数であることがいえる。
しかしこの時点ではまだ極小かどうかは分からない。
$X\bm{z} = \bm{0}$ となる $\bm{z} \neq \bm{0}$ が存在しなければ、$X^TX$ は正定値行列である。</p>
<p>$X \in \mathbb{R}^{N \times (D + 1)}$ が正方行列でない可能性があることに注意すると、
$\bm{z}$ についての同次方程式 $X\bm{z} = \bm{0}$
が自明な解しか持たないための必要十分条件は $\mathrm{rank}\ X = D + 1$、すなわち列フルランクであることである。
一般に $\mathrm{rank}\ X^TX = \mathrm{rank}\ X$ が成り立つ(この事実は今回初めて知った…)。
よって、$\mathrm{rank}\ X = D + 1$ であることと $X^TX$
が正則であることは同値である。$X^TX$ の正則性は仮定していたから、結局 $X^TX$ が正定値であることが分かった。
すなわち、$J(\bm{w}_0)$ は極小値である。</p>
<h3 id="最小値であること">最小値であること</h3>
<p>$J$ のヘッセ行列が $\bm{w}$ によらず $X^TX$、すなわち正定値行列であることに注意すると、$J(\bm{w}_0)$
極小値であるだけでなく、最小値であることも示せる。見やすさのため、
ここでは勾配を $\nabla J(\bm{w})$ 、ヘッセ行列を $\nabla^2 J(\bm{w})$ と書く。
$\bm{w}$ を $\nabla J(\bm{w}) = \bm{0}$ となる点とする。
そこから$\Delta \bm{w}$ だけずれた $J(\bm{w} + \Delta\bm{w})$ を考える。
テイラーの定理より、ある $\bm{d}$ が存在して、</p>
<p>$$
J(\bm{w}_0 + \Delta\bm{w})
= J(\bm{w}_0) +
\nabla J(\bm{w}_0)^T \Delta\bm{w} +
\frac{1}{2} \Delta \bm{w}^T \nabla^2 J(\bm{d}) \Delta \bm{w}
$$</p>
<p>となる。 仮定より $\nabla J(\bm{w}) = \bm{0}$、正定値性より $\Delta \bm{w}^T \nabla^2 J(\bm{d}) \Delta \bm{w} \gt 0$ だから、結局、</p>
<p>$$
J(\bm{w} + \Delta\bm{w}) \gt J(\bm{w})
$$</p>
<p>となる。よって、$\bm{w}$ から $\Delta \bm{w}$ だけずれたとしても、$J$ の値は $J(\bm{w})$ 以下にならない。
よって、$J$ は $\bm{w}$ で大域的な最小値となる。</p>
<h2 id="juliaによる実装">Juliaによる実装</h2>
<p>さて、$X^TX$ が正則であれば、$J$ の最小値は</p>
<p>$$
\begin{aligned}
\bm{w}_0 = \left( X^TX \right)^{-1} X^T \bm{y}
\end{aligned}
$$</p>
<p>で与えられることが分かった。</p>
<p>これを計算するプログラムを書くのは、線型代数のライブラリを持つ言語なら非常に簡単である。
ここではJuliaでプログラムを書いてみる。</p>
<p>ちなみに、Pythonではnumpy.linalgを使えば逆行列とかの計算ができる。
実装を気にすることなく線形回帰をしたい場合は
scikit-learnの<a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">LinearRegression</a>
を使えば良い。scikit-learnのJulia版に<a href="https://scikitlearnjl.readthedocs.io/en/latest/">ScikitLearn.jl</a>がある(内部でscikit-learnを呼び出している模様)ので、
Juliaでも同じことができる。</p>
<p>関連モジュールをインポートし、型のエイリアスを作っておく。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">using</span> <span class="n">Plots</span>
<span class="k">using</span> <span class="n">LinearAlgebra</span>
<span class="k">using</span> <span class="n">Random</span><span class="p">,</span> <span class="n">Distributions</span>

<span class="n">Vec</span> <span class="o">=</span> <span class="kt">Vector</span><span class="p">{</span><span class="kt">Float64</span><span class="p">}</span>
<span class="n">Mat</span> <span class="o">=</span> <span class="kt">Matrix</span><span class="p">{</span><span class="kt">Float64</span><span class="p">}</span>
</code></pre></div><h3 id="サンプルデータの作成">サンプルデータの作成</h3>
<p>ここではデータセットは使わず、データは自前で作る。
ある $\bm{w}$ で作ったデータを元に $\bm{w}_0$ を計算して、これが $\bm{w}$ と近い値なのかどうかを確認する。</p>
<p>まず、適当なデータを作成する関数を作る。 $\bm{w}$ が与えられたとすると、作るデータ $(\bm{x}, y)$ は</p>
<p>$$
y = \bm{w}^T\bm{x} + \varepsilon
$$</p>
<p>に従うものとする。ただし、 $\varepsilon$ は平均 $0$、分散 $\sigma^2$ の正規分布とする。
$\bm{x} = (1, x_1, x_2, \ldots, x_D)$ の最初の成分以外は一様分布乱数で作成し、さらに正規分布乱数で $\varepsilon$ を計算すれば $\bm{y}$
を計算できる。</p>
<p>$\bm{w}$ を元に $N$ 点のデータを作成する関数は以下のようになる。
少ないデータで結果を出したい都合上、正規分布の標準偏差を小さく設定している。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">function</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">w</span> <span class="o">::</span> <span class="n">Vec</span><span class="p">,</span> <span class="n">N</span> <span class="o">::</span> <span class="kt">Int64</span><span class="p">)</span>
  <span class="n">D</span> <span class="o">=</span> <span class="n">length</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
  <span class="nd">@assert</span> <span class="n">D</span> <span class="o">&gt;</span> <span class="mi">1</span>

  <span class="n">d</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
  <span class="n">X</span> <span class="o">=</span> <span class="n">hcat</span><span class="p">(</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="n">rand</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

  <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
<span class="k">end</span>
</code></pre></div><p>作成したデータを試しにプロットしてみたいので、以下のように<code>main</code>関数を作成。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">function</span> <span class="n">main</span><span class="p">()</span>
  <span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>

  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">p1</span> <span class="o">=</span> <span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>

  <span class="n">display</span><span class="p">(</span><span class="n">p1</span><span class="p">)</span>
<span class="k">end</span>

<span class="c"># main関数を実行</span>
<span class="n">main</span><span class="p">()</span>
</code></pre></div><p>ためしにJuliaのREPLで確かめてみる。コードのファイル名は<code>regression.jl</code>とした。</p>
<pre class="cui">
% julia
julia> include("regression.jl")
</pre>

<p><code>generate_data</code>の引数を<code>[1.0, 2.0]</code>にしたので、$y = 1 + 2x$ の点がプロットできている。</p>
<figure><img src="img00.png" width="70%"/>
</figure>

<h3 id="wの計算">wの計算</h3>
<p>次の計算式をそのままJuliaに書き下せば良い。</p>
<p>$$
\begin{aligned}
\bm{w} = \left( X^TX \right)^{-1} X^T \bm{y}
\end{aligned}
$$</p>
<p>Juliaでは行列の転置を<code>'</code>、逆行列を<code>inv</code>で計算できる。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">w</span> <span class="o">=</span>  <span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div><p>…と言いたいところだが、逆行列を計算して左から掛けるよりも、
以下の $\bm{w}$ についての方程式を解く方が、
数値計算の効率が良い。</p>
<p>$$
\begin{aligned}
X^TX\bm{w} = X^T \bm{y}
\end{aligned}
$$</p>
<p>Juliaではこれを<code>\</code>演算子で行える。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">w</span> <span class="o">=</span>  <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">\</span> <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div><p>試しに $\bm{w} = (-1, 2, 4, 1)$ でデータを生成して、そのうえで <code>w</code> を計算してみる。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">function</span> <span class="n">main</span><span class="p">()</span>
  <span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>

  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">p1</span> <span class="o">=</span> <span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>

  <span class="n">w</span> <span class="o">=</span>  <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">\</span> <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">display</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div><p><code>[-1, 2, 4, 1]</code>に近い値になっていることが分かる。</p>
<pre class="cui">
julia> include("regression.jl")
4-element Vector{Float64}:
 -1.06337895821069
  1.9893951252434998
  4.025930296546132
  1.0825520926923566
</pre>

<p>グラフでプロットして確認してみる。$\bm{w} = (1, 2)$ の場合で<code>w</code>を計算し、
それを係数とした直線を引いてみる。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">function</span> <span class="n">main</span><span class="p">()</span>
  <span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>

  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">p1</span> <span class="o">=</span> <span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>

  <span class="c"># wの計算</span>
  <span class="n">w</span> <span class="o">=</span>  <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">\</span> <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>

  <span class="c"># y = w[1] + w[2]*x の描画</span>
  <span class="n">plot_x</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="n">minimum</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">maximum</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
  <span class="n">plot!</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">plot_x</span><span class="p">,</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>

  <span class="n">display</span><span class="p">(</span><span class="n">p1</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div><pre class="cui">
julia> include("regression.jl")
</pre>

<p>データ点に近い直線を引けていることが確認できる。</p>
<figure><img src="img01.png" width="70%"/>
</figure>

<h2 id="問題設定2---基底関数を含む場合">問題設定(2) - 基底関数を含む場合</h2>
<p>$\bm{y} = (y^{(1)}, y^{(2)}, \ldots, y^{(N)})^T,\ \bm{x}_i = (1, x_1^{(i)}, x_2^{(i)}, \ldots, x_D^{(i)})^T, \bm{\phi}(\bm{x}) = (1, \phi_1(\bm{x}), \phi_2(\bm{x}), \ldots, \phi_D(\bm{x}))$
とおく。$(\bm{x}_i, y_i),\ i = 1, 2, \ldots, N$ がデータとして与えられている。このとき、入力と出力の間に</p>
<p>$$
\begin{aligned}
y
&amp;= h_{\bm{w}}(\bm{x})\\
&amp;:= w_0 + w_1\phi_1(\bm{x}) + w_2\phi_2(\bm{x}) + \cdots + w_D\phi_D(\bm{x})\\
&amp;= \bm{w}^T\bm{\phi}(\bm{x})
\end{aligned}
$$</p>
<p>が成り立つと仮定し、そのコスト関数</p>
<p>$$
\begin{aligned}
J(\bm{w}) = \frac{1}{2} \sum_{i=1}^{N} (h_{\bm{w}}(\bm{x}_i) - y^{(i)})^2
\end{aligned}
$$</p>
<p>が最小になるように $\bm{w}$ を決定したい。</p>
<h2 id="コスト関数の最小値を求める-2">コスト関数の最小値を求める (2)</h2>
<p>流れは「コスト関数最小値を求める(1)」とまったく同じ。</p>
<p>$$
\begin{aligned}
\Phi =
\begin{pmatrix}
\bm{\phi}(\bm{x}_1)^T\\
\bm{\phi}(\bm{x}_2)^T\\
\vdots\\
\bm{\phi}(\bm{x}_N)^T
\end{pmatrix}
\end{aligned}
$$</p>
<p>として、</p>
<p>$$
\begin{aligned}
J(\bm{w})
&amp;= \frac{1}{2}
\left( \Phi\bm{w} - \bm{y} \right)^T
\left( \Phi\bm{w} - \bm{y} \right)\\
&amp;= \frac{1}{2}
\left(\bm{w}^T\Phi^T\Phi\bm{w} - 2\bm{y}\Phi\bm{w} + \bm{y}^T\bm{y}\right)
\end{aligned}
$$</p>
<p>が得られる。続いて勾配を求めると、</p>
<p>$$
\begin{aligned}
\frac{\partial J(\bm{w})}{\partial \bm{w}}
&amp;= \Phi^T\Phi\bm{w} - \Phi^T\bm{y}
\end{aligned}
$$</p>
<p>となる。$\Phi^T\Phi$ が正則なら、以下の $\bm{w}$ が存在し、それは $J$ の最小値となる。</p>
<p>$$
\begin{aligned}
&amp; \quad \frac{\partial J(\bm{w})}{\partial \bm{w}} = \bm{0}\\
\Leftrightarrow &amp; \quad \bm{w} = \left(\Phi^T\Phi\right)^{-1} \Phi^T\bm{y}
\end{aligned}
$$</p>
<h2 id="juliaによる実装-2">Juliaによる実装 (2)</h2>
<h3 id="サンプルデータの作成-2">サンプルデータの作成 (2)</h3>
<p>$\Phi$ を計算するために、ベクトル値関数 $\bm{\phi}(\bm{x})$ を引数に持たせる。
$\bm{w}$ の計算にもはや $X$ は必要ないのだが、グラフにデータをプロットする際に必要になるので、
$X$ も返り値に含めている。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">function</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">w</span> <span class="o">::</span> <span class="n">Vec</span><span class="p">,</span> <span class="n">N</span> <span class="o">::</span> <span class="kt">Int64</span><span class="p">;</span> <span class="n">phi</span><span class="o">=</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">D</span> <span class="o">=</span> <span class="n">length</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
  <span class="nd">@assert</span> <span class="n">D</span> <span class="o">&gt;</span> <span class="mi">1</span>

  <span class="n">d</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
  <span class="n">X</span> <span class="o">=</span> <span class="n">hcat</span><span class="p">(</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

  <span class="n">Phi</span> <span class="o">=</span> <span class="n">similar</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">N</span>
    <span class="n">Phi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">Phi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="p">]</span> <span class="o">=</span> <span class="n">phi</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="p">])</span>
  <span class="k">end</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">Phi</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="n">rand</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

  <span class="n">X</span><span class="p">,</span> <span class="n">Phi</span><span class="p">,</span> <span class="n">y</span>
<span class="k">end</span>
</code></pre></div><p>試しに関数 $y = 1 + 2x^2$ によるデータをプロットしてみる。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">function</span> <span class="n">main</span><span class="p">()</span>
  <span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>

  <span class="n">X</span><span class="p">,</span> <span class="n">Phi</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="n">phi</span><span class="o">=</span><span class="n">x</span><span class="o">-&gt;</span><span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span><span class="p">])</span>
  <span class="n">p1</span> <span class="o">=</span> <span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>

  <span class="n">display</span><span class="p">(</span><span class="n">p1</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div><figure><img src="img02.png" width="70%"/>
</figure>

<h3 id="wの計算-2">wの計算 (2)</h3>
<p>これに対応する<code>w</code>を求める。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">function</span> <span class="n">main</span><span class="p">()</span>
  <span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>

  <span class="n">X</span><span class="p">,</span> <span class="n">Phi</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="n">phi</span><span class="o">=</span><span class="n">x</span><span class="o">-&gt;</span><span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">^</span><span class="mi">2</span><span class="p">])</span>
  <span class="n">p1</span> <span class="o">=</span> <span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>

  <span class="n">w</span> <span class="o">=</span>  <span class="p">(</span><span class="n">Phi</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">Phi</span><span class="p">)</span> <span class="o">\</span> <span class="p">(</span><span class="n">Phi</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">display</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

  <span class="n">plot_x</span> <span class="o">=</span> <span class="n">range</span><span class="p">(</span><span class="n">minimum</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">maximum</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
  <span class="n">plot!</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">plot_x</span><span class="p">,</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="o">^</span><span class="mi">2</span><span class="p">)</span>

  <span class="n">display</span><span class="p">(</span><span class="n">p1</span><span class="p">)</span>
<span class="k">end</span>
</code></pre></div><p><code>[1, 2]</code>に近い値をとっている。</p>
<pre class="cui">
julia> include("regression.jl")
2-element Vector{Float64}:
 0.9943755135747157
 1.965007135423543
</pre>

<p>データ点に近い2次関数を描いている。</p>
<figure><img src="img03.png" width="70%"/>
</figure>

<h2 id="計算量">計算量</h2>
<p>以下の $\bm{w}$ を計算するときの時間計算量を考える。</p>
<p>$$
\begin{aligned}
X^TX\bm{w} = X^T \bm{y}
\end{aligned}
$$</p>
<p>Juliaではこれを<code>\</code>演算子で行える。</p>
<div class="highlight"><pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">w</span> <span class="o">=</span>  <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">\</span> <span class="p">(</span><span class="n">X</span><span class="o">&#39;</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div><p>$X^T\bm{y}$ の計算量は、$D \times N$ 行列と $N \times 1$ 行列の積の計算だから $O(DN)$。</p>
<p>$X^TX$ の計算量は、$D \times N$ 行列と $N \times D$ 行列の積の計算だから $O(ND^2)$。</p>
<p><a href="https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#Base.:%5C-Tuple%7BAbstractMatrix%7BT%7D%20where%20T,%20AbstractVecOrMat%7BT%7D%20where%20T%7D">\ のドキュメント</a>によると、
三角行列の場合は交代代入 or 前進代入、そうでない場合はLU分解で三角行列に変換してから解くようだ。$X^TX$ は一般に三角行列ではないのでLU分解され、計算量は $O(D^3)$ となる。</p>
<p>まとめると、計算量は $O(ND^2 + D^3)$ となる。</p>

</article>



</html>
